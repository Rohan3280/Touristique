{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec70bf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Loaded 325 rows from data/places.csv\n",
      "✂️ Split into 325 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rishi\\.conda\\envs\\ai_project106\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RAG Index Built! 1000+ real Indian places loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rishi\\AppData\\Local\\Temp\\ipykernel_34148\\3928493766.py:30: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(\"chroma_db\", exist_ok=True)\n",
    "\n",
    "csv_path = \"data/places.csv\"\n",
    "\n",
    "\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\" Could not find {csv_path}. Please add your places.csv file in the /data folder.\")\n",
    "\n",
    "loader = CSVLoader(csv_path)\n",
    "docs = loader.load()\n",
    "print(f\" Loaded {len(docs)} rows from {csv_path}\")\n",
    "\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(docs)\n",
    "print(f\" Split into {len(chunks)} chunks\")\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "db = Chroma.from_documents(chunks, embeddings, persist_directory=\"chroma_db\")\n",
    "db.persist()\n",
    "\n",
    "print(\" RAG Index Built! 1000+ real Indian places loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0fcc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RAG...\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "print(\"Loading RAG...\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "db = Chroma(persist_directory=\"chroma_db\", embedding_function=embeddings)\n",
    "\n",
    "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "class TripRequest(BaseModel):\n",
    "    preferences: list[str]\n",
    "    duration: int\n",
    "    budget: float\n",
    "    start_city: str = \"Delhi\"\n",
    "\n",
    "def query_ollama(prompt: str) -> str:\n",
    "    payload = {\n",
    "        \"model\": \"phi3:mini\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\"temperature\": 0.7}\n",
    "    }\n",
    "    response = requests.post(OLLAMA_URL, json=payload)\n",
    "    return response.json()[\"response\"]\n",
    "\n",
    "def parse_itinerary(text: str):\n",
    "    pattern = r\"Day (\\d+): (.+?) - (.+?)\\. Stay: (.+?) - ₹([\\d,]+)\\. Food: (.+?) - ₹([\\d,]+)\\. Cost: ₹([\\d,]+)\"\n",
    "    matches = re.findall(pattern, text)\n",
    "    itinerary = []\n",
    "    total = 0\n",
    "    for m in matches:\n",
    "        day, city, dest, stay, stay_cost, food, food_cost, day_cost = m\n",
    "        cost = int(day_cost.replace(\",\", \"\"))\n",
    "        total += cost\n",
    "        itinerary.append({\n",
    "            \"day\": int(day),\n",
    "            \"city\": city.strip(),\n",
    "            \"destinations\": [d.strip() for d in dest.split(\",\")],\n",
    "            \"stay\": f\"{stay.strip()} - ₹{stay_cost}\",\n",
    "            \"food\": f\"{food.strip()} - ₹{food_cost}\",\n",
    "            \"cost\": cost\n",
    "        })\n",
    "    return itinerary, total\n",
    "\n",
    "@app.post(\"/plan\")\n",
    "def plan_trip(req: TripRequest):\n",
    "\n",
    "    query = f\"{', '.join(req.preferences)} near {req.start_city} budget {req.budget}\"\n",
    "    docs = db.similarity_search(query, k=6)\n",
    "    context = \"\\n\".join([\n",
    "        f\"- {d.metadata.get('Place', 'Unknown')} ({d.metadata.get('City', '')}): {d.metadata.get('Category', '')}, ₹{d.metadata.get('Entry Fee', '500')}\"\n",
    "        for d in docs\n",
    "    ])\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are Touristique, India's AI travel planner.\n",
    "\n",
    "User wants: {', '.join(req.preferences)}\n",
    "Duration: {req.duration} days\n",
    "Budget: ₹{req.budget:,}\n",
    "Start: {req.start_city}\n",
    "\n",
    "REAL PLACES:\n",
    "{context}\n",
    "\n",
    "Generate a {req.duration}-day itinerary:\n",
    "- Use only places above\n",
    "- 1-2 destinations per day\n",
    "- Eco-friendly stay\n",
    "- Local food\n",
    "- Stay under budget\n",
    "\n",
    "Format:\n",
    "Day 1: Jaipur - Amber Fort. Stay: Eco Homestay - ₹2,800. Food: Dal Baati - ₹600. Cost: ₹5,400\n",
    "\"\"\".strip()\n",
    "\n",
    "   \n",
    "    print(\"Calling Phi-3 via Ollama...\")\n",
    "    answer = query_ollama(prompt)\n",
    "\n",
    "    try:\n",
    "        itinerary, total = parse_itinerary(answer)\n",
    "        return {\n",
    "            \"itinerary\": itinerary,\n",
    "            \"total_cost\": total,\n",
    "            \"summary\": f\"{req.duration}-day trip under ₹{req.budget:,}\"\n",
    "        }\n",
    "    except:\n",
    "        return {\"raw_output\": answer, \"retrieved_places\": context}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc4ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_project106",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
